package main

import (
	"flag"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"regexp"
	"runtime"
	"sync"

	"github.com/consensys/gnark-crypto/ecc"
	bw6761 "github.com/consensys/gnark-crypto/ecc/bw6-761"
	"github.com/consensys/gnark-crypto/ecc/bw6-761/fp"
	"github.com/consensys/gnark-crypto/ecc/bw6-761/fr"
	"github.com/consensys/gnark-crypto/ecc/bw6-761/kzg"
)

var (
	g1gen bw6761.G1Affine
	g2gen bw6761.G2Affine
)

// ok here is how we proceed;
// first chunk (8.0.18) we are going to read 1<<20 G1 points and 2 G2 points
// all the chunks from 1 to 127 we are going to read 1<<20 G1 points.
// then we build a kzg srs and validate that things looks good.
// then we read previous round chunk 0 (7.0.10) and validate that the ratios hold.

func init() {
	_, _, g1gen, g2gen = bw6761.Generators()
}

var (
	outputSRS        = flag.String("srs", "", "output gnark SRS") // optional flag to set the output gnark SRS generated by this program
	noSubgroupChecks = flag.Bool("no-subgroup-checks", false, "disable subgroup checks")
)

type chunk struct {
	tauG1   [1 << 20]bw6761.G1Affine
	tauG2   [2]bw6761.G2Affine
	isFirst bool
}

func (c *chunk) read(round, chunkID int) error {
	c.isFirst = chunkID == 0
	// open the chunk file
	f, err := openChunk(round, chunkID)
	if err != nil {
		return err
	}
	defer f.Close()

	// skip first 64 bytes
	if _, err := f.Seek(64, 0); err != nil {
		return err
	}

	// read 1<<20 G1 points
	var tryReadErr error
	var buf [fp.Bytes]byte
	tryReadElement := func() (e fp.Element) {
		if tryReadErr != nil {
			return
		}
		_, tryReadErr = f.Read(buf[:])
		if tryReadErr == nil {
			e, tryReadErr = fp.LittleEndian.Element(&buf)
		}
		return
	}

	for i := 0; i < 1<<20; i++ {
		c.tauG1[i].X = tryReadElement()
		c.tauG1[i].Y = tryReadElement()
	}
	if tryReadErr != nil {
		return tryReadErr
	}

	if chunkID > 0 {
		return nil
	}

	// first chunk.
	// read 2 G2 points
	c.tauG2[0].X = tryReadElement()
	c.tauG2[0].Y = tryReadElement()
	c.tauG2[1].X = tryReadElement()
	c.tauG2[1].Y = tryReadElement()
	return tryReadErr
}

func (c *chunk) isValid() bool {
	l1, l2 := linearCombinationG1(c.tauG1[:])
	return sameRatio(l1, l2, c.tauG2[1], c.tauG2[0])
}

func (c *chunk) verify() error {
	if *noSubgroupChecks {
		return nil
	}
	var errors []error
	var lock sync.Mutex
	execute(1<<20, func(start, end int) {
		for i := start; i < end; i++ {
			if !c.tauG1[i].IsInSubGroup() {
				lock.Lock()
				errors = append(errors, fmt.Errorf("g1 point %d is not in subgroup", i))
				lock.Unlock()
				return
			}
		}
	})
	if len(errors) > 0 {
		return fmt.Errorf("g1 points are not in subgroup: %v", errors)
	}

	if c.isFirst {
		// ensure that the points are on the correct subgroup
		if !c.tauG2[0].IsInSubGroup() {
			return fmt.Errorf("g2 point 0 is not in subgroup")
		}
		if !c.tauG2[1].IsInSubGroup() {
			return fmt.Errorf("g2 point 1 is not in subgroup")
		}

	}

	return nil
}

// This tool is dirty with many constants and hardcoded values.
// It aims to parse 2 rounds of the Aleo ceremony and verify that the points are on the curve and in the subgroup.
// Then it creates a KZG srs from the last round of the ceremony, in the gnark format.
func main() {
	flag.Parse()

	// process the first chunk of the last round
	var currChunk chunk
	if err := currChunk.read(8, 0); err != nil {
		log.Fatalf("failed to read chunk file: %s", err.Error())
	}
	var prevChunkPrevRound chunk
	if err := prevChunkPrevRound.read(7, 0); err != nil {
		log.Fatalf("failed to read chunk file: %s", err.Error())
	}

	if err := currChunk.verify(); err != nil {
		log.Fatalf("failed to verify firstChunkCurrent: %s", err.Error())
	}
	if !currChunk.isValid() {
		log.Fatalf("firstChunkCurrent is not valid")
	}
	if err := prevChunkPrevRound.verify(); err != nil {
		log.Fatalf("failed to verify firstChunkPrevious: %s", err.Error())
	}

	// ensure tauG1[0] is the generator
	if !currChunk.tauG1[0].Equal(&g1gen) {
		log.Fatalf("tauG1[0] is not the generator")
	}
	// same with previous chunk
	if !prevChunkPrevRound.tauG1[0].Equal(&g1gen) {
		log.Fatalf("tauG1[0] is not the generator")
	}
	// same with tauG2[0]
	if !currChunk.tauG2[0].Equal(&g2gen) {
		log.Fatalf("tauG2[0] is not the generator")
	}
	// same with previous chunk
	if !prevChunkPrevRound.tauG2[0].Equal(&g2gen) {
		log.Fatalf("tauG2[0] is not the generator")
	}

	// ensure tauG1[1] and tauG2[1] are the same ratio
	if !sameRatio(currChunk.tauG1[1], prevChunkPrevRound.tauG1[1], prevChunkPrevRound.tauG2[1], currChunk.tauG2[1]) {
		log.Fatalf("tauG1[1] and tauG2[1] are not the same ratio")
	}

	// build the SRS
	var srs kzg.SRS
	srs.Pk.G1 = make([]bw6761.G1Affine, 0, 1<<21)
	srs.Vk.G1 = g1gen
	srs.Vk.G2[0] = g2gen
	srs.Vk.Lines[0] = bw6761.PrecomputeLines(srs.Vk.G2[0])
	srs.Vk.G2[1] = currChunk.tauG2[1]
	srs.Vk.Lines[1] = bw6761.PrecomputeLines(srs.Vk.G2[1])
	srs.Pk.G1 = append(srs.Pk.G1, currChunk.tauG1[:]...)

	// read the next chunks and append tauG1 to the SRS
	var nextChunk chunk
	nextChunk.tauG2 = currChunk.tauG2
	for i := 1; i < 128; i++ {
		if err := nextChunk.read(8, i); err != nil {
			log.Fatalf("failed to read chunk file: %s", err.Error())
		}
		if err := nextChunk.verify(); err != nil {
			log.Fatalf("failed to verify nextChunk: %s", err.Error())
		}
		if !nextChunk.isValid() {
			log.Fatalf("nextChunk is not valid")
		}
		srs.Pk.G1 = append(srs.Pk.G1, nextChunk.tauG1[:]...)
	}

	log.Printf("built srs of len %d", len(srs.Pk.G1))

	srsSanityCheck(&srs)

	log.Println("done validiting, writing SRS to disk")

	// write gnark SRS to file
	if *outputSRS == "" {
		log.Println("no output file specified, exiting")
		return
	}

	wout, err := os.Create(*outputSRS)
	if err != nil {
		log.Fatalf("failed to create output file: %v", err)
	}

	if _, err := srs.WriteRawTo(wout); err != nil {
		log.Fatalf("failed to write gnark SRS to file: %v", err)
	}

	log.Println("done writing SRS to disk")
}

func srsSanityCheck(srs *kzg.SRS) {
	// we can now use the SRS to verify a proof
	// create a polynomial
	f := randomPolynomial(len(srs.Pk.G1) - 1)

	// commit the polynomial
	digest, err := kzg.Commit(f, srs.Pk)
	if err != nil {
		log.Fatalf("failed to commit polynomial: %v", err)
	}

	// compute opening proof at a random point
	var point fr.Element
	point.SetString("4321")
	proof, err := kzg.Open(f, point, srs.Pk)
	if err != nil {
		log.Fatalf("failed to open polynomial: %v", err)
	}

	// verify the claimed valued
	expected := eval(f, point)
	if !proof.ClaimedValue.Equal(&expected) {
		log.Fatal("inconsistent claimed value")
	}

	// verify correct proof
	err = kzg.Verify(&digest, &proof, point, srs.Vk)
	if err != nil {
		log.Fatalf("failed to verify proof: %v", err)
	}
}

func randomPolynomial(size int) []fr.Element {
	f := make([]fr.Element, size)
	for i := 0; i < size; i++ {
		f[i].SetRandom()
	}
	return f
}

// eval returns p(point) where p is interpreted as a polynomial
// ∑_{i<len(p)}p[i]Xⁱ
func eval(p []fr.Element, point fr.Element) fr.Element {
	var res fr.Element
	n := len(p)
	res.Set(&p[n-1])
	for i := n - 2; i >= 0; i-- {
		res.Mul(&res, &point).Add(&res, &p[i])
	}
	return res
}

func openChunk(round, chunkID int) (*os.File, error) {
	const roundsRootDir = "./rounds/"

	// build a regexp and list files in the dir that match it
	pattern := fmt.Sprintf("^%d.%d.*", round, chunkID)
	reg, err := regexp.Compile(pattern)
	if err != nil {
		return nil, err
	}

	files, err := ioutil.ReadDir(roundsRootDir)
	if err != nil {
		return nil, err
	}

	// then open the first match (we know we have one and only one match)
	for _, file := range files {
		if reg.MatchString(file.Name()) {
			log.Printf("opening file %s\n", file.Name())
			return os.Open(roundsRootDir + file.Name())
		}
	}

	// if no match found, return error.
	return nil, fmt.Errorf("no file matches the pattern: %s", pattern)
}

func execute(nbIterations int, work func(int, int), maxCpus ...int) {

	nbTasks := runtime.NumCPU()
	if len(maxCpus) == 1 {
		nbTasks = maxCpus[0]
	}
	nbIterationsPerCpus := nbIterations / nbTasks

	// more CPUs than tasks: a CPU will work on exactly one iteration
	if nbIterationsPerCpus < 1 {
		nbIterationsPerCpus = 1
		nbTasks = nbIterations
	}

	var wg sync.WaitGroup

	extraTasks := nbIterations - (nbTasks * nbIterationsPerCpus)
	extraTasksOffset := 0

	for i := 0; i < nbTasks; i++ {
		wg.Add(1)
		_start := i*nbIterationsPerCpus + extraTasksOffset
		_end := _start + nbIterationsPerCpus
		if extraTasks > 0 {
			_end++
			extraTasks--
			extraTasksOffset++
		}
		go func() {
			work(_start, _end)
			wg.Done()
		}()
	}

	wg.Wait()
}

// sameRatio checks that e(a₁, a₂) = e(b₁, b₂)
func sameRatio(a1, b1 bw6761.G1Affine, a2, b2 bw6761.G2Affine) bool {
	// we already know that a1, b1, a2, b2 are in the correct subgroup
	// if !a1.IsInSubGroup() || !b1.IsInSubGroup() || !a2.IsInSubGroup() || !b2.IsInSubGroup() {
	// 	panic("invalid point not in subgroup")
	// }
	var na2 bw6761.G2Affine
	na2.Neg(&a2)
	res, err := bw6761.PairingCheck(
		[]bw6761.G1Affine{a1, b1},
		[]bw6761.G2Affine{na2, b2})
	if err != nil {
		panic(err)
	}
	return res
}

var initROnce sync.Once
var rVector []fr.Element

// L1 = ∑ rᵢAᵢ, L2 = ∑ rᵢAᵢ₊₁ in G1
func linearCombinationG1(A []bw6761.G1Affine) (L1, L2 bw6761.G1Affine) {
	nc := runtime.NumCPU()
	n := len(A)
	initROnce.Do(func() {
		rVector = make([]fr.Element, n-1)
		for i := 0; i < n-1; i++ {
			rVector[i].SetRandom()
		}
	})
	chDone := make(chan struct{})
	go func() {
		L1.MultiExp(A[:n-1], rVector, ecc.MultiExpConfig{NbTasks: nc / 2})
		close(chDone)
	}()
	L2.MultiExp(A[1:], rVector, ecc.MultiExpConfig{NbTasks: nc / 2})
	<-chDone
	return
}
